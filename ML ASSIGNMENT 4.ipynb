{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0340e150",
   "metadata": {},
   "source": [
    "# Logistic Regression and SVM for Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e664be82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21fe0af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditcardfraud.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2ac2da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82450</td>\n",
       "      <td>1.314539</td>\n",
       "      <td>0.590643</td>\n",
       "      <td>-0.666593</td>\n",
       "      <td>0.716564</td>\n",
       "      <td>0.301978</td>\n",
       "      <td>-1.125467</td>\n",
       "      <td>0.388881</td>\n",
       "      <td>-0.288390</td>\n",
       "      <td>-0.132137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170307</td>\n",
       "      <td>-0.429655</td>\n",
       "      <td>-0.141341</td>\n",
       "      <td>-0.200195</td>\n",
       "      <td>0.639491</td>\n",
       "      <td>0.399476</td>\n",
       "      <td>-0.034321</td>\n",
       "      <td>0.031692</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50554</td>\n",
       "      <td>-0.798672</td>\n",
       "      <td>1.185093</td>\n",
       "      <td>0.904547</td>\n",
       "      <td>0.694584</td>\n",
       "      <td>0.219041</td>\n",
       "      <td>-0.319295</td>\n",
       "      <td>0.495236</td>\n",
       "      <td>0.139269</td>\n",
       "      <td>-0.760214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202287</td>\n",
       "      <td>0.578699</td>\n",
       "      <td>-0.092245</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>-0.246466</td>\n",
       "      <td>-0.380057</td>\n",
       "      <td>-0.396030</td>\n",
       "      <td>-0.112901</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55125</td>\n",
       "      <td>-0.391128</td>\n",
       "      <td>-0.245540</td>\n",
       "      <td>1.122074</td>\n",
       "      <td>-1.308725</td>\n",
       "      <td>-0.639891</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>-0.701304</td>\n",
       "      <td>-0.027315</td>\n",
       "      <td>-2.628854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133485</td>\n",
       "      <td>0.117403</td>\n",
       "      <td>-0.191748</td>\n",
       "      <td>-0.488642</td>\n",
       "      <td>-0.309774</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.163716</td>\n",
       "      <td>0.239582</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116572</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>1.065093</td>\n",
       "      <td>-0.987421</td>\n",
       "      <td>-0.029567</td>\n",
       "      <td>0.176376</td>\n",
       "      <td>-1.348539</td>\n",
       "      <td>0.775644</td>\n",
       "      <td>0.134843</td>\n",
       "      <td>-0.149734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355576</td>\n",
       "      <td>0.907570</td>\n",
       "      <td>-0.018454</td>\n",
       "      <td>-0.126269</td>\n",
       "      <td>-0.339923</td>\n",
       "      <td>-0.150285</td>\n",
       "      <td>-0.023634</td>\n",
       "      <td>0.042330</td>\n",
       "      <td>57.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90434</td>\n",
       "      <td>1.848433</td>\n",
       "      <td>0.373364</td>\n",
       "      <td>0.269272</td>\n",
       "      <td>3.866438</td>\n",
       "      <td>0.088062</td>\n",
       "      <td>0.970447</td>\n",
       "      <td>-0.721945</td>\n",
       "      <td>0.235983</td>\n",
       "      <td>0.683491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103563</td>\n",
       "      <td>0.620954</td>\n",
       "      <td>0.197077</td>\n",
       "      <td>0.692392</td>\n",
       "      <td>-0.206530</td>\n",
       "      <td>-0.021328</td>\n",
       "      <td>-0.019823</td>\n",
       "      <td>-0.042682</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>160243</td>\n",
       "      <td>-2.783865</td>\n",
       "      <td>1.596824</td>\n",
       "      <td>-2.084844</td>\n",
       "      <td>2.512986</td>\n",
       "      <td>-1.446749</td>\n",
       "      <td>-0.828496</td>\n",
       "      <td>-0.732262</td>\n",
       "      <td>-0.203329</td>\n",
       "      <td>-0.347046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203563</td>\n",
       "      <td>0.293268</td>\n",
       "      <td>0.199568</td>\n",
       "      <td>0.146868</td>\n",
       "      <td>0.163602</td>\n",
       "      <td>-0.624085</td>\n",
       "      <td>-1.333100</td>\n",
       "      <td>0.428634</td>\n",
       "      <td>156.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>110547</td>\n",
       "      <td>-1.532810</td>\n",
       "      <td>2.232752</td>\n",
       "      <td>-5.923100</td>\n",
       "      <td>3.386708</td>\n",
       "      <td>-0.153443</td>\n",
       "      <td>-1.419748</td>\n",
       "      <td>-3.878576</td>\n",
       "      <td>1.444656</td>\n",
       "      <td>-1.465542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632505</td>\n",
       "      <td>-0.070838</td>\n",
       "      <td>-0.490291</td>\n",
       "      <td>-0.359983</td>\n",
       "      <td>0.050678</td>\n",
       "      <td>1.095671</td>\n",
       "      <td>0.471741</td>\n",
       "      <td>-0.106667</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>70071</td>\n",
       "      <td>-0.440095</td>\n",
       "      <td>1.137239</td>\n",
       "      <td>-3.227080</td>\n",
       "      <td>3.242293</td>\n",
       "      <td>-2.033998</td>\n",
       "      <td>-1.618415</td>\n",
       "      <td>-3.028013</td>\n",
       "      <td>0.764555</td>\n",
       "      <td>-1.801937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764187</td>\n",
       "      <td>-0.275578</td>\n",
       "      <td>-0.343572</td>\n",
       "      <td>0.233085</td>\n",
       "      <td>0.606434</td>\n",
       "      <td>-0.315433</td>\n",
       "      <td>0.768291</td>\n",
       "      <td>0.459623</td>\n",
       "      <td>227.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>93879</td>\n",
       "      <td>-13.086519</td>\n",
       "      <td>7.352148</td>\n",
       "      <td>-18.256576</td>\n",
       "      <td>10.648505</td>\n",
       "      <td>-11.731476</td>\n",
       "      <td>-3.659167</td>\n",
       "      <td>-14.873658</td>\n",
       "      <td>8.810473</td>\n",
       "      <td>-5.418204</td>\n",
       "      <td>...</td>\n",
       "      <td>2.761157</td>\n",
       "      <td>-0.266162</td>\n",
       "      <td>-0.412861</td>\n",
       "      <td>0.519952</td>\n",
       "      <td>-0.743909</td>\n",
       "      <td>-0.167808</td>\n",
       "      <td>-2.498300</td>\n",
       "      <td>-0.711066</td>\n",
       "      <td>30.31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>50706</td>\n",
       "      <td>-8.461845</td>\n",
       "      <td>6.866198</td>\n",
       "      <td>-11.838269</td>\n",
       "      <td>4.194211</td>\n",
       "      <td>-6.923097</td>\n",
       "      <td>-3.221147</td>\n",
       "      <td>-7.553497</td>\n",
       "      <td>6.015618</td>\n",
       "      <td>-2.466143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918244</td>\n",
       "      <td>-0.715366</td>\n",
       "      <td>0.210747</td>\n",
       "      <td>-0.060211</td>\n",
       "      <td>0.509535</td>\n",
       "      <td>-0.257284</td>\n",
       "      <td>1.170027</td>\n",
       "      <td>0.229301</td>\n",
       "      <td>99.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time         V1        V2         V3         V4         V5        V6  \\\n",
       "0     82450   1.314539  0.590643  -0.666593   0.716564   0.301978 -1.125467   \n",
       "1     50554  -0.798672  1.185093   0.904547   0.694584   0.219041 -0.319295   \n",
       "2     55125  -0.391128 -0.245540   1.122074  -1.308725  -0.639891  0.008678   \n",
       "3    116572  -0.060302  1.065093  -0.987421  -0.029567   0.176376 -1.348539   \n",
       "4     90434   1.848433  0.373364   0.269272   3.866438   0.088062  0.970447   \n",
       "..      ...        ...       ...        ...        ...        ...       ...   \n",
       "595  160243  -2.783865  1.596824  -2.084844   2.512986  -1.446749 -0.828496   \n",
       "596  110547  -1.532810  2.232752  -5.923100   3.386708  -0.153443 -1.419748   \n",
       "597   70071  -0.440095  1.137239  -3.227080   3.242293  -2.033998 -1.618415   \n",
       "598   93879 -13.086519  7.352148 -18.256576  10.648505 -11.731476 -3.659167   \n",
       "599   50706  -8.461845  6.866198 -11.838269   4.194211  -6.923097 -3.221147   \n",
       "\n",
       "            V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0     0.388881 -0.288390 -0.132137  ... -0.170307 -0.429655 -0.141341   \n",
       "1     0.495236  0.139269 -0.760214  ...  0.202287  0.578699 -0.092245   \n",
       "2    -0.701304 -0.027315 -2.628854  ... -0.133485  0.117403 -0.191748   \n",
       "3     0.775644  0.134843 -0.149734  ...  0.355576  0.907570 -0.018454   \n",
       "4    -0.721945  0.235983  0.683491  ...  0.103563  0.620954  0.197077   \n",
       "..         ...       ...       ...  ...       ...       ...       ...   \n",
       "595  -0.732262 -0.203329 -0.347046  ...  0.203563  0.293268  0.199568   \n",
       "596  -3.878576  1.444656 -1.465542  ...  0.632505 -0.070838 -0.490291   \n",
       "597  -3.028013  0.764555 -1.801937  ...  0.764187 -0.275578 -0.343572   \n",
       "598 -14.873658  8.810473 -5.418204  ...  2.761157 -0.266162 -0.412861   \n",
       "599  -7.553497  6.015618 -2.466143  ...  0.918244 -0.715366  0.210747   \n",
       "\n",
       "          V24       V25       V26       V27       V28  Amount  Class  \n",
       "0   -0.200195  0.639491  0.399476 -0.034321  0.031692    0.76      0  \n",
       "1    0.013723 -0.246466 -0.380057 -0.396030 -0.112901    4.18      0  \n",
       "2   -0.488642 -0.309774  0.008100  0.163716  0.239582   15.00      0  \n",
       "3   -0.126269 -0.339923 -0.150285 -0.023634  0.042330   57.00      0  \n",
       "4    0.692392 -0.206530 -0.021328 -0.019823 -0.042682    0.00      0  \n",
       "..        ...       ...       ...       ...       ...     ...    ...  \n",
       "595  0.146868  0.163602 -0.624085 -1.333100  0.428634  156.00      1  \n",
       "596 -0.359983  0.050678  1.095671  0.471741 -0.106667    0.76      1  \n",
       "597  0.233085  0.606434 -0.315433  0.768291  0.459623  227.30      1  \n",
       "598  0.519952 -0.743909 -0.167808 -2.498300 -0.711066   30.31      1  \n",
       "599 -0.060211  0.509535 -0.257284  1.170027  0.229301   99.99      1  \n",
       "\n",
       "[600 rows x 31 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddea4251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a81afb",
   "metadata": {},
   "source": [
    "### processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9564b3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'Time' column\n",
    "data.drop('Time', axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16b2b0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
       "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ffc2b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -0.443051\n",
       "1     -0.427821\n",
       "2     -0.379637\n",
       "3     -0.192602\n",
       "4     -0.446435\n",
       "         ...   \n",
       "595    0.248265\n",
       "596   -0.443051\n",
       "597    0.565779\n",
       "598   -0.311458\n",
       "599   -0.001159\n",
       "Name: Amount, Length: 600, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the 'Amount' column using a standard scaler\n",
    "scaler = StandardScaler()\n",
    "data['Amount'] = scaler.fit_transform(data[['Amount']])\n",
    "data['Amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6356e2b",
   "metadata": {},
   "source": [
    "### Spliting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e08ede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "394f0a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Train a logistic regression model on the training set\n",
    "logistic_model = LogisticRegression(solver = 'liblinear', random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d3b1ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Evaluate the logistic regression model\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "conf_matrix_logistic = confusion_matrix(y_test, y_pred_logistic)\n",
    "class_report_logistic = classification_report(y_test, y_pred_logistic)\n",
    "accuracy_score(y_pred_logistic,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a903f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9416666666666667"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking accuracy with sag\n",
    "logistic_model = LogisticRegression(solver = 'sag', random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "conf_matrix_logistic = confusion_matrix(y_test, y_pred_logistic)\n",
    "class_report_logistic = classification_report(y_test, y_pred_logistic)\n",
    "accuracy_score(y_pred_logistic,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e63d0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking accuracy with saga\n",
    "logistic_model = LogisticRegression(solver = 'saga', random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "conf_matrix_logistic = confusion_matrix(y_test, y_pred_logistic)\n",
    "class_report_logistic = classification_report(y_test, y_pred_logistic)\n",
    "accuracy_score(y_pred_logistic,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "63a1909f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9416666666666667"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking accuracy with lbfgs\n",
    "logistic_model = LogisticRegression(solver = 'lbfgs', random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "conf_matrix_logistic = confusion_matrix(y_test, y_pred_logistic)\n",
    "class_report_logistic = classification_report(y_test, y_pred_logistic)\n",
    "accuracy_score(y_pred_logistic,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0517cc44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9416666666666667"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking accuracy with newton-cg, so we are choosing newton-cg as the highest\n",
    "logistic_model = LogisticRegression(solver = 'newton-cg', random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "conf_matrix_logistic = confusion_matrix(y_test, y_pred_logistic)\n",
    "class_report_logistic = classification_report(y_test, y_pred_logistic)\n",
    "accuracy_score(y_pred_logistic,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bfe574f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "576b2fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[59,  3],\n",
       "       [ 4, 54]], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix_logistic #The confusion matrix is a table that is often used to describe the performance of a classification model on a set of test data for which the true values are known. In the context of binary classification (two classes, typically denoted as positive and negative), the confusion matrix has four entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "139967a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.94      0.95      0.94        62\\n           1       0.95      0.93      0.94        58\\n\\n    accuracy                           0.94       120\\n   macro avg       0.94      0.94      0.94       120\\nweighted avg       0.94      0.94      0.94       120\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_report_logistic #The classification_report function provides a more comprehensive evaluation of the model's performance by calculating several metrics for each class. In binary classification, there are two classes: positive (usually denoted as 1) and negative (usually denoted as 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f70682",
   "metadata": {},
   "source": [
    "## Svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a891570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear', random_state=42)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Train an SVM model on the training set using kernel as linear\n",
    "svm_model = SVC(kernel = 'linear',random_state=42)\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff075517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Evaluate the SVM model\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "class_report_svm = classification_report(y_test, y_pred_svm)\n",
    "accuracy_score(y_pred_svm,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0cb89e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train an SVM model on the training set using kernel as poly\n",
    "svm_model = SVC(kernel = 'poly',random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "class_report_svm = classification_report(y_test, y_pred_svm)\n",
    "accuracy_score(y_pred_svm,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b944e1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train an SVM model on the training set using kernel as rbf\n",
    "svm_model = SVC(kernel = 'rbf',random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "class_report_svm = classification_report(y_test, y_pred_svm)\n",
    "accuracy_score(y_pred_svm,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b553452f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9416666666666667"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train an SVM model on the training set using kernel as sigmoid\n",
    "svm_model = SVC(kernel = 'sigmoid',random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "class_report_svm = classification_report(y_test, y_pred_svm)\n",
    "accuracy_score(y_pred_svm,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5652c2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train an SVM model on the training set using kernel as rbf we will using rbf as it is showing highest accuracy\n",
    "svm_model = SVC(kernel = 'rbf',random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "class_report_svm = classification_report(y_test, y_pred_svm)\n",
    "accuracy_score(y_pred_svm,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "693a8e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.91      1.00      0.95        62\\n           1       1.00      0.90      0.95        58\\n\\n    accuracy                           0.95       120\\n   macro avg       0.96      0.95      0.95       120\\nweighted avg       0.95      0.95      0.95       120\\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_report_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4801dff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62,  0],\n",
       "       [ 6, 52]], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7743b29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3687714",
   "metadata": {},
   "source": [
    "## so it is evident that svm is more accurate than logistic regression with higher accuracy score of 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7530958a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 8. Tune hyperparameters using grid search cross-validation\n",
    "# Logistic Regression hyperparameter tuning\n",
    "param_grid_logistic = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid_logistic = GridSearchCV(LogisticRegression(random_state=42), param_grid_logistic, cv=5)\n",
    "grid_logistic.fit(X_train, y_train)\n",
    "best_params_logistic = grid_logistic.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c3ed4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec622919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM hyperparameter tuning\n",
    "param_grid_svm = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "grid_svm = GridSearchCV(SVC(random_state=42), param_grid_svm, cv=5)\n",
    "grid_svm.fit(X_train, y_train)\n",
    "best_params_svm = grid_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56201716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bd52c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.1, kernel=&#x27;linear&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.1, kernel=&#x27;linear&#x27;, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=0.1, kernel='linear', random_state=42)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. Train models with optimal hyperparameters\n",
    "optimal_logistic_model = LogisticRegression(**best_params_logistic, random_state=42)\n",
    "optimal_logistic_model.fit(X_train, y_train)\n",
    "\n",
    "optimal_svm_model = SVC(**best_params_svm, random_state=42)\n",
    "optimal_svm_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d23c7cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Evaluate models with optimal hyperparameters\n",
    "y_pred_optimal_logistic = optimal_logistic_model.predict(X_test)\n",
    "conf_matrix_optimal_logistic = confusion_matrix(y_test, y_pred_optimal_logistic)\n",
    "class_report_optimal_logistic = classification_report(y_test, y_pred_optimal_logistic)\n",
    "\n",
    "y_pred_optimal_svm = optimal_svm_model.predict(X_test)\n",
    "conf_matrix_optimal_svm = confusion_matrix(y_test, y_pred_optimal_svm)\n",
    "class_report_optimal_svm = classification_report(y_test, y_pred_optimal_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b5c93e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_optimal_logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e38ad716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[61,  1],\n",
       "       [ 4, 54]], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix_optimal_logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf01f698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.94      0.98      0.96        62\\n           1       0.98      0.93      0.96        58\\n\\n    accuracy                           0.96       120\\n   macro avg       0.96      0.96      0.96       120\\nweighted avg       0.96      0.96      0.96       120\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_report_optimal_logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4b2986aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_optimal_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "362dde57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62,  0],\n",
       "       [ 5, 53]], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix_optimal_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2608db3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.93      1.00      0.96        62\\n           1       1.00      0.91      0.95        58\\n\\n    accuracy                           0.96       120\\n   macro avg       0.96      0.96      0.96       120\\nweighted avg       0.96      0.96      0.96       120\\n'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_report_optimal_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11fb58a",
   "metadata": {},
   "source": [
    "## It is evident that after tuning the accuracy of svm and logistic regg has increased to 96% for both. svm has better prediction than logistic reggression.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b518b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0860bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71df855f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
